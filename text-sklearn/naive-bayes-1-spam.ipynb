{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Filtering\n",
    "\n",
    "### Overview\n",
    "\n",
    "We all hate spam, so developing a classifier to classify email as spam or not spam is useful.  \n",
    "\n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 20-30 minutes\n",
    "\n",
    "### Notes\n",
    "\n",
    "We can do Naive Bayes classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "We will load the dataframe into pandas.  Since the outcome label is \"ham\" or \"spam\", that will be our label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data_location = 'https://elephantscale-public.s3.amazonaws.com/data/spam/SMSSpamCollection.txt'\n",
    "data_location = '/data/spam/SMSSpamCollection.txt'\n",
    "\n",
    "dataset = pd.read_csv(data_location, sep='\\t')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO :  Count spam/ham\n",
    "## Hint : group by 'isspam'\n",
    "## Question : Is there a data skew?\n",
    "dataset.groupby(\"???\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Vectorize Using TF/IDF\n",
    "\n",
    "Let's use tf/idf for vecorization at first.  TF/IDF will take and count the instances of each term, and then divide by the total frequecy of that term in the entire dataset.  \n",
    "\n",
    "This leads to very highly dimensional data, because every word in the document will lead to a dimension in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vec', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer())])\n",
    "\n",
    "## TODO : vectorize the 'text' column\n",
    "x = pipeline.fit_transform(dataset['???'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can leave y as 'spam' / 'ham'\n",
    "# y = dataset['isspam']\n",
    "\n",
    "## TODO : encode y\n",
    "## Hint : use hte 'isspam' column\n",
    "y = pd.factorize(dataset['???'])[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Use training / test split of 80%/20%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train, y_test = train_test_split(x,y,  test_size=???)\n",
    "## to control train/test split set random_state to a number\n",
    "# x_train,x_test,y_train, y_test = train_test_split(x,y, random_state=0, test_size=0.3)\n",
    "\n",
    "print (\"x_train :\" , x_train.shape )\n",
    "print (\"x_test :\", x_test.shape)\n",
    "print (\"y_train :\", y_train.shape)\n",
    "print (\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB ()\n",
    "\n",
    "##TODO : fit on (x_train, y_train)\n",
    "model = nb.fit(x_train, ???)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Inspect the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coef : ', model.coef_)\n",
    "print('intercept' , model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1: Predict on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : predict on 'x_test'\n",
    "y_pred = model.predict(???)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame ({'label' : y_test, 'prediction' : y_pred })\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 :  Score\n",
    "\n",
    "Let's look at how our model performs.  We will do an accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : score the model using (x_test, y_test)\n",
    "model.score(???,???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## TODO : score the model using (y_test, y_pred)\n",
    "accuracy_score(y_test, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Confusion Matrix\n",
    "\n",
    "Hmmm.. the positive case didn't do as well as the negative case. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot confusion matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "import my_utils\n",
    "\n",
    "my_utils.plot_confusion_matrix(cm, target_names=['ham','spam'], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics calculated from Confusion Matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "pd.DataFrame(list(precision_recall_fscore_support(y_test, y_pred)),\n",
    "             columns=['ham', 'spam'],\n",
    "             index=['Precision', 'Recall', \"F1\", \"Support\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 :  ROC Curve & AUC\n",
    "\n",
    "For this to work, 'y' must be encoded as a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8:  Run your own data!\n",
    "\n",
    "Now it's your turn!   Make a new dataframe with some sample test data of your own creation.  Make some \"spammy\" SMSes and some ordinary ones.  See how our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.DataFrame ( { 'text' : [\n",
    "                                     'can we meet for lunch?',\n",
    "                                     'win win win instant tickets!',\n",
    "                                     'ultra cheap medications!!!',\n",
    "                                     'your text here'\n",
    "]})\n",
    "\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_x = pipeline.transform(mydata['text'])\n",
    "my_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred = model.predict(my_x)\n",
    "my_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['prediction'] = my_pred\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN : How will you defeat this algorithm? :-) \n",
    "\n",
    "If you are spammer, how can you defeat this algorithm?\n",
    "\n",
    "<img src=\"../assets/images/come-tothe-dark-side-iin-we-have-cookies.png\" />\n",
    "\n",
    "## Further Reading\n",
    "Checkout [Amazon Comprehend](https://us-west-2.console.aws.amazon.com/comprehend/v2/home?region=us-west-2#welcome) to parse natural text and extract meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
